{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: /Users/brad/Desktop/Plant_Pal/Modeling\n",
      "Data Directory: /Users/brad/Desktop/Plant_Pal/Modeling/../Data\n"
     ]
    }
   ],
   "source": [
    "base_directory = os.getcwd()\n",
    "data_directory = base_directory + \"/../Data\"\n",
    "print(\"Base Directory:\", base_directory)\n",
    "print(\"Data Directory:\", data_directory)\n",
    "\n",
    "data_dirs = os.listdir(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for data_dir in data_dirs:\n",
    "    if data_dir == \".DS_Store\":\n",
    "        continue\n",
    "    species, label = data_dir.split('___')  # how species and label are delineated in filenames\n",
    "    image_paths = os.listdir(os.path.join(data_directory, data_dir))\n",
    "    for image in image_paths:\n",
    "        entry = [species, label, os.path.join(data_dir, image)]\n",
    "        data.append(entry)\n",
    "\n",
    "data_df = pd.DataFrame(data, columns=['Species', 'Condition', 'Image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 77836\n",
      "Validation set size: 9730\n",
      "Test set size: 9730\n",
      "Adjusted Training set size: 11052\n",
      "tensor([[[-0.9363, -1.1075, -1.1418,  ...,  0.2453,  0.1083,  0.5878],\n",
      "         [-0.7650, -1.0562, -1.2617,  ...,  0.2282,  0.2967,  0.2111],\n",
      "         [-0.9020, -1.0733, -1.1075,  ...,  0.6906,  0.9474,  0.0912],\n",
      "         ...,\n",
      "         [ 1.3755,  1.4269,  1.2214,  ...,  0.8961,  0.5193,  0.7077],\n",
      "         [ 1.2385,  1.3242,  1.6667,  ...,  0.7248,  0.6221,  0.7077],\n",
      "         [ 1.2728,  1.1187,  1.3070,  ...,  0.7248,  0.8618,  0.8104]],\n",
      "\n",
      "        [[-1.0028, -1.1779, -1.2129,  ...,  0.1702,  0.0301,  0.5203],\n",
      "         [-0.8277, -1.1253, -1.3354,  ...,  0.1527,  0.2227,  0.1352],\n",
      "         [-0.9678, -1.1429, -1.1779,  ...,  0.6254,  0.8880,  0.0126],\n",
      "         ...,\n",
      "         [ 1.5007,  1.5532,  1.3431,  ...,  0.9755,  0.5903,  0.7829],\n",
      "         [ 1.3606,  1.4482,  1.7983,  ...,  0.8004,  0.6954,  0.7829],\n",
      "         [ 1.3957,  1.2381,  1.4307,  ...,  0.8004,  0.9405,  0.8880]],\n",
      "\n",
      "        [[-0.7936, -0.9678, -1.0027,  ...,  0.3916,  0.2522,  0.7402],\n",
      "         [-0.6193, -0.9156, -1.1247,  ...,  0.3742,  0.4439,  0.3568],\n",
      "         [-0.7587, -0.9330, -0.9678,  ...,  0.8448,  1.1062,  0.2348],\n",
      "         ...,\n",
      "         [ 1.7337,  1.7860,  1.5768,  ...,  1.1411,  0.7576,  0.9494],\n",
      "         [ 1.5942,  1.6814,  2.0300,  ...,  0.9668,  0.8622,  0.9494],\n",
      "         [ 1.6291,  1.4722,  1.6640,  ...,  0.9668,  1.1062,  1.0539]]])\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train (80%) and temp (20%)\n",
    "train_df, temp_df = train_test_split(data_df, test_size=0.2, stratify=data_df[['Species', 'Condition']], random_state=2)\n",
    "\n",
    "# Split the temp data into validation (10%) and test (10%)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[['Species', 'Condition']], random_state=2)\n",
    "\n",
    "print(\"Training set size:\", len(train_df))\n",
    "print(\"Validation set size:\", len(val_df))\n",
    "print(\"Test set size:\", len(test_df))\n",
    "# Adjust the training dataframe to ensure no more than 300 samples of any particular condition\n",
    "train_df = train_df.groupby('Condition').apply(lambda x: x.sample(n=min(len(x), 300), random_state=2)).reset_index(drop=True)\n",
    "\n",
    "print(\"Adjusted Training set size:\", len(train_df))\n",
    "\n",
    "train_set = CustomDataset(train_df['Image'])\n",
    "val_set = CustomDataset(val_df['Image'])\n",
    "test_set = CustomDataset(test_df['Image'])\n",
    "\n",
    "print(train_set.__getitem__(0))\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brad/env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')\n",
    "model = torchvision.models.resnet50(weights=\"IMAGENET1K_V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(learning_rate=0.001):\n",
    "    early_stopper = Historian(early_stopping=3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    running_vl = 0.0\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        train_loss = criterion(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_tl += train_loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "    return running_tl / len(training_loader)\n",
    "\n",
    "def cross_validation(rates=[0.1, 0.000001]):\n",
    "    best_rate = None\n",
    "    best_loss = float('inf')\n",
    "    for rate in np.arange(rates[0], rates[1], -0.1):\n",
    "        loss = train(learning_rate=rate)\n",
    "        print(f'Learning rate: {rate}, Loss: {loss}')\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_rate = rate\n",
    "    print(f'Best learning rate: {best_rate}, Best loss: {best_loss}')\n",
    "    return best_rate, best_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
